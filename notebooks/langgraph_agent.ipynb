{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from src.config import parse_config\n",
    "import os\n",
    "\n",
    "root_dir = Path(os.getcwd()).parent\n",
    "config_path = root_dir / 'agents' / 'langgraph' / 'config.yaml'\n",
    "agent_path = root_dir / 'agents' / 'langgraph' / 'agent.py'\n",
    "\n",
    "mlflow_config = mlflow.models.ModelConfig(development_config=config_path)\n",
    "sls_config = parse_config(mlflow_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    }
   ],
   "source": [
    "from src.retrievers import get_vector_retriever\n",
    "retriever = get_vector_retriever(sls_config)\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "model = ChatDatabricks(endpoint=sls_config.model.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup some nodes to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'rephrase_template' from 'src.prompts' (/Users/scott.mckean/Repos/retrieval_with_highlighting/src/prompts.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, AIMessage\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_state\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnodes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     make_query_vector_database_node, \n\u001b[1;32m      6\u001b[0m     make_context_generation_node,\n\u001b[1;32m      7\u001b[0m     make_simple_generation_node\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m state \u001b[38;5;241m=\u001b[39m get_state(sls_config)\n\u001b[1;32m     11\u001b[0m retriever_node \u001b[38;5;241m=\u001b[39m make_query_vector_database_node(retriever, sls_config)\n",
      "File \u001b[0;32m~/Repos/retrieval_with_highlighting/src/nodes.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableLambda\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphState, StreamState\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chat_template, context_template, rephrase_template\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_documents\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     format_generation_user,\n\u001b[1;32m      9\u001b[0m     format_generation_assistant,\n\u001b[1;32m     10\u001b[0m     get_last_user_message,\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'rephrase_template' from 'src.prompts' (/Users/scott.mckean/Repos/retrieval_with_highlighting/src/prompts.py)"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from src.states import get_state\n",
    "from src.nodes import (\n",
    "    make_query_vector_database_node, \n",
    "    make_context_generation_node,\n",
    "    make_simple_generation_node\n",
    ")\n",
    "\n",
    "state = get_state(sls_config)\n",
    "retriever_node = make_query_vector_database_node(retriever, sls_config)\n",
    "simple_generation_node = make_simple_generation_node(model, sls_config)\n",
    "context_generation_node = make_context_generation_node(model, sls_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section builds a simple generation graph. It expects an input state with a dictionary of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.messages.input_examples import input_example\n",
    "input_state = {'messages':[{'type':'user', 'content':'What is SQL?'}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use langchain's convert_to_messages to convert the input state to a list of messages. This is convenient because OpenAI uses 'role' and LangChain uses 'type'. We centralize on LangChain's message type for now.\n",
    "\n",
    "This expects a list of dictionaries with 'type' and 'content' keys. Will fail is the entire {'messages':[{'type':'user', 'content':'What is SQL?'}]} is passed in.\n",
    "\n",
    "We can use the convert_to_openai_messages function to convert the list of LangChain messages back to a list of dictionaries with 'role' and 'content' keys.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages.utils import convert_to_messages\n",
    "lc_msgs = convert_to_messages(input_example['messages'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'So, yeah. Yes, it does support streaming, allowing you to watch your favorite shows and movies online.'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"generate\", simple_generation_node)\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our rephrasing generation node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "  {'role': 'user',\n",
       "   'content': 'What streaming capabilities does Apache Spark support for processing real-time data and incremental computation, as part of its unified analytics engine for large-scale data processing?'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"generate\", rephrase_generation_node)\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check context generation node with no context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"I don't know. The provided context is empty, so I have no information to determine if something supports streaming.\"}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"generate\", context_generation_node)\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check retriever only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'}],\n",
       " 'context': 'Passage: Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date =\\\\n Document URI: \\\\nPassage: 27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,\\\\n Document URI: \\\\nPassage: Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,\\\\n Document URI: \\\\n',\n",
       " 'documents': [Document(metadata={'img_path': '', 'filename': 'FAA-2021-0268-0002.pdf', 'type': 'text', 'id': 103079215112.0}, page_content='Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date ='),\n",
       "  Document(metadata={'img_path': '', 'filename': 'FAA-2021-0268-0002.pdf', 'type': 'text', 'id': 103079215116.0}, page_content='27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,'),\n",
       "  Document(metadata={'img_path': '', 'filename': 'FAA-2021-0268-0002.pdf', 'type': 'text', 'id': 111669149709.0}, page_content='Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"retrieve\", retriever_node)\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section builds a rag graph without history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"retrieve\", retriever_node)\n",
    "workflow.add_node(\"generate_w_context\", context_generation_node)\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate_w_context\")\n",
    "workflow.add_edge(\"generate_w_context\", END)\n",
    "app = workflow.compile()\n",
    "result = app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'message': {'role': 'assistant',\n",
       "    'content': 'I do not know. The context appears to be a collection of unrelated data points with various codes, dates, and page numbers, but it does not provide any information about streaming capabilities.',\n",
       "    'refusal': None,\n",
       "    'name': None,\n",
       "    'tool_calls': None,\n",
       "    'tool_call_id': None},\n",
       "   'index': 0,\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}],\n",
       " 'usage': None,\n",
       " 'id': None,\n",
       " 'model': None,\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1738970510,\n",
       " 'custom_outputs': {'message_history': [{'role': 'user',\n",
       "    'content': 'What is Apache Spark'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "   {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "   {'role': 'tool',\n",
       "    'content': 'Passage: Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date =\\\\n Document URI: \\\\nPassage: 27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,\\\\n Document URI: \\\\nPassage: Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,\\\\n Document URI: \\\\n'},\n",
       "   {'role': 'tool',\n",
       "    'content': [{'id': None,\n",
       "      'metadata': {'img_path': '',\n",
       "       'filename': 'FAA-2021-0268-0002.pdf',\n",
       "       'type': 'text',\n",
       "       'id': 103079215112.0},\n",
       "      'page_content': 'Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date =',\n",
       "      'type': 'Document'},\n",
       "     {'id': None,\n",
       "      'metadata': {'img_path': '',\n",
       "       'filename': 'FAA-2021-0268-0002.pdf',\n",
       "       'type': 'text',\n",
       "       'id': 103079215116.0},\n",
       "      'page_content': '27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,',\n",
       "      'type': 'Document'},\n",
       "     {'id': None,\n",
       "      'metadata': {'img_path': '',\n",
       "       'filename': 'FAA-2021-0268-0002.pdf',\n",
       "       'type': 'text',\n",
       "       'id': 111669149709.0},\n",
       "      'page_content': 'Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,',\n",
       "      'type': 'Document'}]}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from maud.agent.utils import graph_state_to_chat_type\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = app | RunnableLambda(graph_state_to_chat_type)\n",
    "chain.invoke(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
